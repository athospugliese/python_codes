{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1I7J7IiZicLa6xwzQzcv16ZUbf4IDvlyL",
      "authorship_tag": "ABX9TyOudjBSeP822BII0ehg+Zyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athospugliesedev/python_codes/blob/main/dp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObfSj9u0-vcg"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "# URL da pasta do Google Drive\n",
        "folder_url = \"https://drive.google.com/drive/folders/1PWFA2drwOjMjMSgQP6mAJs3NeVxC_HMJ?hl=en\"\n",
        "\n",
        "# Diretório de destino para os arquivos baixados\n",
        "download_dir = \"output/\"\n",
        "\n",
        "# Lista de URLs dos arquivos na pasta\n",
        "file_urls = [\n",
        "    \"https://drive.google.com/drive/folders/1lV24o4Y8v4iTD7-MwzlkigwYtEcfttqj?usp=drive_link\", \"https://drive.google.com/drive/folders/1PWFA2drwOjMjMSgQP6mAJs3NeVxC_HMJ?usp=drive_link\",   # Adicione as URLs dos arquivos aqui\n",
        "]\n",
        "\n",
        "# Certifique-se de que o diretório de destino exista\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Função para fazer o download de um lote de arquivos\n",
        "def download_batch(file_urls, download_dir):\n",
        "    for url in file_urls:\n",
        "        gdown.download(url, os.path.join(download_dir, os.path.basename(url)))\n",
        "\n",
        "# Divida a lista de URLs em lotes de no máximo 50 URLs\n",
        "batch_size = 50\n",
        "for i in range(0, len(file_urls), batch_size):\n",
        "    batch = file_urls[i:i + batch_size]\n",
        "    download_batch(batch, download_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wCgaKBlA_NR",
        "outputId": "e7399467-34f5-44ea-fc6f-5885792334c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/parse_url.py:35: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/drive/folders/1lV24o4Y8v4iTD7-MwzlkigwYtEcfttqj?usp=drive_link\n",
            "To: /content/output/1lV24o4Y8v4iTD7-MwzlkigwYtEcfttqj?usp=drive_link\n",
            "703kB [00:00, 2.29MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/drive/folders/1PWFA2drwOjMjMSgQP6mAJs3NeVxC_HMJ?usp=drive_link\n",
            "To: /content/output/1PWFA2drwOjMjMSgQP6mAJs3NeVxC_HMJ?usp=drive_link\n",
            "702kB [00:00, 1.79MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "Rkm2Y3zo_WZo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2  # Substitua pelo número de classes em seu conjunto de dados\n",
        "image_size = (224, 224)  # Tamanho das imagens\n",
        "train_data_dir = \"../../content/drive/MyDrive/ML/\"  # Caminho para os dados de treinamento no Google Drive\n"
      ],
      "metadata": {
        "id": "QOdgns_b_ubP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,  # Normalização dos valores de pixel\n",
        "    validation_split=0.2  # Porcentagem de dados de validação\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=32,  # Escolha o tamanho do lote adequado\n",
        "    class_mode='categorical',  # Para classificação multiclasse\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6jsr3uo_uhI",
        "outputId": "9340de2b-3ff2-430b-9b73-9ae2e795fd40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 966 images belonging to 2 classes.\n",
            "Found 240 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina o modelo com a nova arquitetura\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(image_size[0], image_size[1], 3)),  # InputLayer com tamanho das imagens\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Imprima um resumo do modelo\n",
        "model.summary()\n",
        "\n",
        "# Defina os hiperparâmetros de treinamento\n",
        "batch_size = 128\n",
        "epochs = 10  # Ajuste o número de épocas conforme necessário\n",
        "\n",
        "# Compile o modelo com a função de perda, otimizador e métricas desejados\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Treine o modelo com os geradores de dados que você configurou anteriormente\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czxbFNpx_un_",
        "outputId": "399be73c-b51b-4463-bcdf-7c95120326a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 373248)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               95551744  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95627906 (364.79 MB)\n",
            "Trainable params: 95627906 (364.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "22/31 [====================>.........] - ETA: 39s - loss: 3.9622 - accuracy: 0.5634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 250s 8s/step - loss: 2.9882 - accuracy: 0.5735 - val_loss: 0.7203 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 5s 155ms/step - loss: 0.6304 - accuracy: 0.6988 - val_loss: 0.8312 - val_accuracy: 0.6125\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 5s 157ms/step - loss: 0.4487 - accuracy: 0.8157 - val_loss: 0.5836 - val_accuracy: 0.7417\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 5s 168ms/step - loss: 0.2846 - accuracy: 0.8954 - val_loss: 0.6095 - val_accuracy: 0.7542\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 4s 132ms/step - loss: 0.1686 - accuracy: 0.9410 - val_loss: 0.7820 - val_accuracy: 0.7417\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 4s 134ms/step - loss: 0.1080 - accuracy: 0.9638 - val_loss: 0.8676 - val_accuracy: 0.7208\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 5s 161ms/step - loss: 0.1273 - accuracy: 0.9669 - val_loss: 0.8915 - val_accuracy: 0.7583\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0680 - accuracy: 0.9865 - val_loss: 0.9360 - val_accuracy: 0.7417\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 4s 129ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 1.2802 - val_accuracy: 0.7583\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 5s 172ms/step - loss: 0.0305 - accuracy: 0.9948 - val_loss: 1.1691 - val_accuracy: 0.7458\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d4162d5c3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NH7dA2NZCUK",
        "outputId": "0e539888-9776-4335-e724-68fe82232611"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "31/31 [==============================] - 5s 148ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 1.3126 - val_accuracy: 0.7542\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 5s 151ms/step - loss: 0.0313 - accuracy: 0.9928 - val_loss: 1.0842 - val_accuracy: 0.7333\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 5s 163ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 1.4432 - val_accuracy: 0.7583\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 4s 132ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 1.3428 - val_accuracy: 0.7583\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 5s 163ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.4224 - val_accuracy: 0.7583\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 4s 141ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4706 - val_accuracy: 0.7625\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 1.3381 - val_accuracy: 0.7375\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 5s 164ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 1.5452 - val_accuracy: 0.7292\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 5s 154ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7263 - val_accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 5s 164ms/step - loss: 5.0334e-04 - accuracy: 1.0000 - val_loss: 1.8228 - val_accuracy: 0.7542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d41580737c0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(train_generator)\n",
        "print(f\"Acurácia no conjunto de teste: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnXV-yy0ZDmN",
        "outputId": "78337227-8d45-4c5f-9c7c-9b32ed02b01b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2/31 [>.............................] - ETA: 4s - loss: 2.5194e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 5s 153ms/step - loss: 2.3509e-04 - accuracy: 1.0000\n",
            "Acurácia no conjunto de teste: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "# Carregue e redimensione a imagem\n",
        "img = load_img(\"../../content/61IYKDIPBgL._AC_UF894,1000_QL80_.jpg\", target_size=(image_size[0], image_size[1]))\n",
        "img = img_to_array(img)\n",
        "\n",
        "# Pré-processamento da imagem (normalização)\n",
        "img = preprocess_input(img)\n"
      ],
      "metadata": {
        "id": "ghC4o9UKZE9i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(np.expand_dims(img, axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3TJjTxBdse_",
        "outputId": "b9a1847b-7377-4426-8c2e-d2ee4d9da3f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_probabilities = predictions[0]  # Probabilidades para as duas classes\n",
        "class_predicted = \"dog\" if class_probabilities[0] > class_probabilities[1] else \"robot\"\n"
      ],
      "metadata": {
        "id": "hHZM7B4feV5t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = np.argmax(predictions)\n"
      ],
      "metadata": {
        "id": "dCjNvY6ZduJM"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}