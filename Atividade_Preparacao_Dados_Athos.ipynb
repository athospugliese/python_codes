{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athospugliesedev/python_codes/blob/main/Atividade_Preparacao_Dados_Athos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h align=centre><font size = 8>Preparação e transformação dos dados </font></h>\n"
      ],
      "metadata": {
        "id": "-2JcSDF3in9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "\n",
        "1: Import required libraries - Pandas, Numpy, and required classes for this task - ColumnTransformer, OneHotEncoder, LabelEncoder."
      ],
      "metadata": {
        "id": "aq4V3GgLiv7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "ac4cObUHjTN9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Load the dataset --> titanic.csv\n",
        "\n",
        "2: Start by loading the Titanic dataset into a pandas data frame. This can be done using the pd.read_csv function. The dataset's name is 'titanic.csv'.\n"
      ],
      "metadata": {
        "id": "z4tKh4hKiyVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Caminho para o arquivo CSV no Google Drive\n",
        "caminho_arquivo = '/content/drive/My Drive/dataset/titanic.csv'\n",
        "\n",
        "# Fazer a leitura do arquivo CSV\n",
        "base = pd.read_csv(caminho_arquivo, sep=';', header=None, names=['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'])\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(base.head())\n",
        "\n",
        "# Load the Titanic dataset into DataFrame base\n",
        "\n",
        "# Check the column names\n",
        "print(\"Column Names:\")\n",
        "print(base.columns)\n",
        "\n",
        "# Inspect the DataFrame\n",
        "print(\"DataFrame Head:\")\n",
        "print(base.head())\n"
      ],
      "metadata": {
        "id": "2GaqHTcjjTuD",
        "outputId": "17f68053-58a1-42e1-eaf9-8c98284f3fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0  PassengerId  Survived  Pclass   \n",
            "1            2         1       1   \n",
            "2            4         1       1   \n",
            "3            7         0       1   \n",
            "4           11         1       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                                               Name     Sex   Age  SibSp   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "3                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
            "4                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
            "\n",
            "   Parch    Ticket     Fare  Cabin  Embarked  \n",
            "0  Parch    Ticket     Fare  Cabin  Embarked  \n",
            "1      0  PC 17599  712.833    C85         C  \n",
            "2      0    113803     53.1   C123         S  \n",
            "3      0     17463  518.625    E46         S  \n",
            "4      1   PP 9549     16.7     G6         S  \n",
            "Column Names:\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n",
            "DataFrame Head:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0  PassengerId  Survived  Pclass   \n",
            "1            2         1       1   \n",
            "2            4         1       1   \n",
            "3            7         0       1   \n",
            "4           11         1       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                                               Name     Sex   Age  SibSp   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "3                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
            "4                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
            "\n",
            "   Parch    Ticket     Fare  Cabin  Embarked  \n",
            "0  Parch    Ticket     Fare  Cabin  Embarked  \n",
            "1      0  PC 17599  712.833    C85         C  \n",
            "2      0    113803     53.1   C123         S  \n",
            "3      0     17463  518.625    E46         S  \n",
            "4      1   PP 9549     16.7     G6         S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify  target and dependent variables  "
      ],
      "metadata": {
        "id": "CrHisUsm0jtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n",
        "target_variable = 'Survived'\n",
        "\n",
        "dependent_variables = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "print(\"Target Variable:\", target_variable)\n",
        "print(\"Dependent Variables:\", dependent_variables)\n"
      ],
      "metadata": {
        "id": "4jLDNktx0kM2",
        "outputId": "4fd64a07-ce47-4f0f-af33-95bb0ba7968c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Variable: Survived\n",
            "Dependent Variables: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify the categorical data\n",
        "3: Identify the categorical features in your dataset that need to be encoded. You can store these feature names in a list for easy access later."
      ],
      "metadata": {
        "id": "vt9dgKm8i06i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n",
        "print(base.dtypes)\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = base.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Categorical Features:\")\n",
        "print(categorical_features)\n"
      ],
      "metadata": {
        "id": "1glm2tctjUSr",
        "outputId": "b9a8ae8c-5b03-44e8-cd05-e27028b99972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    object\n",
            "Survived       object\n",
            "Pclass         object\n",
            "Name           object\n",
            "Sex            object\n",
            "Age            object\n",
            "SibSp          object\n",
            "Parch          object\n",
            "Ticket         object\n",
            "Fare           object\n",
            "Cabin          object\n",
            "Embarked       object\n",
            "dtype: object\n",
            "Categorical Features:\n",
            "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Implement an instance of the ColumnTransformer class\n",
        "\n",
        "4: To apply OneHotEncoding to these categorical features, create an instance of the ColumnTransformer class. Make sure to pass the OneHotEncoder() as an argument along with the list of categorical features.\n"
      ],
      "metadata": {
        "id": "VTlrTg77i3Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "transformed_data = column_transformer.fit_transform(base)\n",
        "\n",
        "print(transformed_data)\n"
      ],
      "metadata": {
        "id": "vhCLrBgijU8z",
        "outputId": "2669b290-810f-4775-b0a7-15663b9b10cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 'Ticket' 'Fare' 'Cabin']\n",
            " [0.0 1.0 0.0 ... 'PC 17599' '712.833' 'C85']\n",
            " [0.0 1.0 0.0 ... '113803' '53.1' 'C123']\n",
            " ...\n",
            " [0.0 1.0 0.0 ... '11767' '831.583' 'C50']\n",
            " [0.0 1.0 0.0 ... '112053' '30.0' 'B42']\n",
            " [0.0 0.0 1.0 ... '111369' '30.0' 'C148']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply the fit_transform method on the instance of ColumnTransformer\n",
        "\n",
        "5: Use the fit_transform method on the instance of ColumnTransformer to apply the OneHotEncoding.\n",
        "\n",
        "6: The output of the fit_transform method should be converted into a NumPy array for further use\n"
      ],
      "metadata": {
        "id": "HJvMzloIi5Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n",
        "\n",
        "transformed_data = column_transformer.fit_transform(base)\n",
        "\n",
        "transformed_data_array = np.array(transformed_data)\n",
        "\n",
        "print(transformed_data_array)\n"
      ],
      "metadata": {
        "id": "vDveInL7jVhB",
        "outputId": "5b83d45e-53fa-44fc-c9af-3d6aed3bdd1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 'Ticket' 'Fare' 'Cabin']\n",
            " [0.0 1.0 0.0 ... 'PC 17599' '712.833' 'C85']\n",
            " [0.0 1.0 0.0 ... '113803' '53.1' 'C123']\n",
            " ...\n",
            " [0.0 1.0 0.0 ... '11767' '831.583' 'C50']\n",
            " [0.0 1.0 0.0 ... '112053' '30.0' 'B42']\n",
            " [0.0 0.0 1.0 ... '111369' '30.0' 'C148']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the output into a NumPy array\n"
      ],
      "metadata": {
        "id": "1mRCqnnVi6zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n",
        "\n",
        "transformed_data_array = np.array(transformed_data)\n",
        "\n",
        "print(transformed_data_array)\n"
      ],
      "metadata": {
        "id": "TBpW_cgqjV_y",
        "outputId": "b8fc2fc1-5e87-451d-c98d-1cd1208cd676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 'Ticket' 'Fare' 'Cabin']\n",
            " [0.0 1.0 0.0 ... 'PC 17599' '712.833' 'C85']\n",
            " [0.0 1.0 0.0 ... '113803' '53.1' 'C123']\n",
            " ...\n",
            " [0.0 1.0 0.0 ... '11767' '831.583' 'C50']\n",
            " [0.0 1.0 0.0 ... '112053' '30.0' 'B42']\n",
            " [0.0 0.0 1.0 ... '111369' '30.0' 'C148']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Use LabelEncoder to encode binary categorical data\n",
        "7: The 'Survived' column in your dataset is the dependent variable. This is a binary categorical variable that should be encoded using LabelEncoder."
      ],
      "metadata": {
        "id": "0xtgcmDoi9A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "base['Survived_encoded'] = label_encoder.fit_transform(base['Survived'])\n",
        "\n",
        "print(base['Survived_encoded'])\n"
      ],
      "metadata": {
        "id": "M2aA-sWHjWic",
        "outputId": "0252ae83-ef33-44ea-ac57-95d502f5b96f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      2\n",
            "1      1\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "179    1\n",
            "180    0\n",
            "181    1\n",
            "182    1\n",
            "183    1\n",
            "Name: Survived_encoded, Length: 184, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Print the updated matrix of features and the dependent variable vector\n",
        "\n",
        "8.  Print the updated matrix of features and the dependent variable vector\n",
        "\n"
      ],
      "metadata": {
        "id": "7TfOSkb4i-9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code\n",
        "\n",
        "features_matrix = transformed_data_array[:, :-1]\n",
        "print(\"Matrix of Features:\")\n",
        "print(features_matrix)\n",
        "\n",
        "dependent_variable_vector = transformed_data_array[:, -1]\n",
        "print(\"\\nDependent Variable Vector:\")\n",
        "print(dependent_variable_vector)\n"
      ],
      "metadata": {
        "id": "PKP0eS8UjYzF",
        "outputId": "f809e236-dcc7-48b4-eb5e-2abf50c70316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix of Features:\n",
            "[[1.0 0.0 0.0 ... 'Parch' 'Ticket' 'Fare']\n",
            " [0.0 1.0 0.0 ... '0' 'PC 17599' '712.833']\n",
            " [0.0 1.0 0.0 ... '0' '113803' '53.1']\n",
            " ...\n",
            " [0.0 1.0 0.0 ... '1' '11767' '831.583']\n",
            " [0.0 1.0 0.0 ... '0' '112053' '30.0']\n",
            " [0.0 0.0 1.0 ... '0' '111369' '30.0']]\n",
            "\n",
            "Dependent Variable Vector:\n",
            "['Cabin' 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'D33'\n",
            " 'B30' 'C83' 'F33' 'F G73' 'C23 C25 C27' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
            " 'B58 B60' 'E101' 'D26' 'D47' 'C123' 'B86' 'F2' 'C2' 'B19' 'A7' 'C49' 'F4'\n",
            " 'F2' 'B4' 'B80' 'G6' 'A31' 'D36' 'D15' 'C93' 'C83' 'C78' 'D35' 'G6' 'C87'\n",
            " 'B77' 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'B49' 'D' 'C22 C26' 'B58 B60'\n",
            " 'C22 C26' 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'D' 'B18'\n",
            " 'C124' 'C91' 'C2' 'E40' 'T' 'F2' 'C23 C25 C27' 'F33' 'E33' 'D37' 'B35'\n",
            " 'E50' 'C82' 'B96 B98' 'D36' 'G6' 'C78' 'E10' 'C52' 'E44' 'B96 B98'\n",
            " 'C23 C25 C27' 'A34' 'C104' 'C111' 'C92' 'E38' 'E12' 'E63' 'D' 'B49' 'C93'\n",
            " 'B37' 'C30' 'D20' 'C22 C26' 'B79' 'C65' 'E25' 'D46' 'F33' 'B73' 'B18'\n",
            " 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'E67' 'C101' 'E25' 'E44' 'C68' 'A10'\n",
            " 'E68' 'B41' 'D20' 'A20' 'C125' 'F4' 'D19' 'D50' 'D9' 'A23' 'B50' 'B35'\n",
            " 'D33' 'A26' 'D48' 'E58' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'C68'\n",
            " 'F G63' 'C62 C64' 'E24' 'E24' 'C90' 'C126' 'F G73' 'C45' 'E101' 'E8' 'B5'\n",
            " 'B101' 'C46' 'B57 B59 B63 B66' 'B22' 'D30' 'E121' 'B77' 'B96 B98' 'D11'\n",
            " 'E77' 'B3' 'B20' 'D6' 'B82 B84' 'D17' 'B96 B98' 'A36' 'E8' 'B69' 'E121'\n",
            " 'E49' 'D28' 'E17' 'D17' 'A24' 'D35' 'B51 B53 B55' 'C50' 'B42' 'C148']\n",
            "Matrix of Features:\n",
            "[[1.0 0.0 0.0 ... 'Parch' 'Ticket' 'Fare']\n",
            " [0.0 1.0 0.0 ... '0' 'PC 17599' '712.833']\n",
            " [0.0 1.0 0.0 ... '0' '113803' '53.1']\n",
            " ...\n",
            " [0.0 1.0 0.0 ... '1' '11767' '831.583']\n",
            " [0.0 1.0 0.0 ... '0' '112053' '30.0']\n",
            " [0.0 0.0 1.0 ... '0' '111369' '30.0']]\n",
            "\n",
            "Dependent Variable Vector:\n",
            "['Cabin' 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'D33'\n",
            " 'B30' 'C83' 'F33' 'F G73' 'C23 C25 C27' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
            " 'B58 B60' 'E101' 'D26' 'D47' 'C123' 'B86' 'F2' 'C2' 'B19' 'A7' 'C49' 'F4'\n",
            " 'F2' 'B4' 'B80' 'G6' 'A31' 'D36' 'D15' 'C93' 'C83' 'C78' 'D35' 'G6' 'C87'\n",
            " 'B77' 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'B49' 'D' 'C22 C26' 'B58 B60'\n",
            " 'C22 C26' 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'D' 'B18'\n",
            " 'C124' 'C91' 'C2' 'E40' 'T' 'F2' 'C23 C25 C27' 'F33' 'E33' 'D37' 'B35'\n",
            " 'E50' 'C82' 'B96 B98' 'D36' 'G6' 'C78' 'E10' 'C52' 'E44' 'B96 B98'\n",
            " 'C23 C25 C27' 'A34' 'C104' 'C111' 'C92' 'E38' 'E12' 'E63' 'D' 'B49' 'C93'\n",
            " 'B37' 'C30' 'D20' 'C22 C26' 'B79' 'C65' 'E25' 'D46' 'F33' 'B73' 'B18'\n",
            " 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'E67' 'C101' 'E25' 'E44' 'C68' 'A10'\n",
            " 'E68' 'B41' 'D20' 'A20' 'C125' 'F4' 'D19' 'D50' 'D9' 'A23' 'B50' 'B35'\n",
            " 'D33' 'A26' 'D48' 'E58' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'C68'\n",
            " 'F G63' 'C62 C64' 'E24' 'E24' 'C90' 'C126' 'F G73' 'C45' 'E101' 'E8' 'B5'\n",
            " 'B101' 'C46' 'B57 B59 B63 B66' 'B22' 'D30' 'E121' 'B77' 'B96 B98' 'D11'\n",
            " 'E77' 'B3' 'B20' 'D6' 'B82 B84' 'D17' 'B96 B98' 'A36' 'E8' 'B69' 'E121'\n",
            " 'E49' 'D28' 'E17' 'D17' 'A24' 'D35' 'B51 B53 B55' 'C50' 'B42' 'C148']\n"
          ]
        }
      ]
    }
  ]
}